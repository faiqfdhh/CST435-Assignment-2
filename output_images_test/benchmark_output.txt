============================================================
IMAGE PROCESSING PARALLELISM BENCHMARK
============================================================
Number of images: 1
CPU cores available: 12
Input folder: ./input_images_test
Output folder: ./output_images_test
Timestamp: 2025-12-30 22:37:24

------------------------------------------------------------
Step 1: Sequential Processing (no parallelism)
------------------------------------------------------------
Processing images one by one...
Total time (sequential): 7.9536 seconds
Average time per image: 7.9536 seconds

========================================
Testing with 1 worker(s)
========================================

[Pixel-level parallelism]
multiprocessing.Pool with 1 workers...
  Time: 8.6229s | Speedup: 0.92x | Efficiency: 92.24%
concurrent.futures with 1 workers...
  Time: 8.6399s | Speedup: 0.92x | Efficiency: 92.06%

[Image-level parallelism]
multiprocessing.Pool with 1 workers...
  Time: 8.2907s | Speedup: 0.96x | Efficiency: 95.93%
concurrent.futures with 1 workers...
  Time: 8.5655s | Speedup: 0.93x | Efficiency: 92.86%

========================================
Testing with 2 worker(s)
========================================

[Pixel-level parallelism]
multiprocessing.Pool with 2 workers...
  Time: 4.9901s | Speedup: 1.59x | Efficiency: 79.69%
concurrent.futures with 2 workers...
  Time: 5.0595s | Speedup: 1.57x | Efficiency: 78.60%

[Image-level parallelism]
multiprocessing.Pool with 2 workers...
  Time: 8.3869s | Speedup: 0.95x | Efficiency: 47.42%
concurrent.futures with 2 workers...
  Time: 8.6102s | Speedup: 0.92x | Efficiency: 46.19%

========================================
Testing with 4 worker(s)
========================================

[Pixel-level parallelism]
multiprocessing.Pool with 4 workers...
  Time: 3.4218s | Speedup: 2.32x | Efficiency: 58.11%
concurrent.futures with 4 workers...
  Time: 3.4359s | Speedup: 2.31x | Efficiency: 57.87%

[Image-level parallelism]
multiprocessing.Pool with 4 workers...
  Time: 8.8403s | Speedup: 0.90x | Efficiency: 22.49%
concurrent.futures with 4 workers...
  Time: 8.4837s | Speedup: 0.94x | Efficiency: 23.44%

========================================
Testing with 8 worker(s)
========================================

[Pixel-level parallelism]
multiprocessing.Pool with 8 workers...
  Time: 2.3889s | Speedup: 3.33x | Efficiency: 41.62%
concurrent.futures with 8 workers...
  Time: 2.4596s | Speedup: 3.23x | Efficiency: 40.42%

[Image-level parallelism]
multiprocessing.Pool with 8 workers...
  Time: 8.8217s | Speedup: 0.90x | Efficiency: 11.27%
concurrent.futures with 8 workers...
  Time: 8.5072s | Speedup: 0.93x | Efficiency: 11.69%

================================================================================
PHASE 3: SCALABILITY ANALYSIS
================================================================================


================================================================================
PIXEL-LEVEL PARALLELISM STRATEGY
================================================================================

Multiprocessing:
----------------------------------------

Workers    Time (s)     Speedup      Efficiency  
1          8.6229       0.92        x 92.24%      
2          4.9901       1.59        x 79.69%      
4          3.4218       2.32        x 58.11%      
8          2.3889       3.33        x 41.62%      

Scalability Metrics:
  • Best speedup: 3.33x (at 8 workers)
  • Speedup with 8 workers: 3.33x (Ideal: 8x)
  • Scaling efficiency: 41.6%
  • Efficiency trend: 92.2% → 79.7% → 58.1% → 41.6%

Bottleneck Analysis:
  ⚠️  POOR SCALING detected:
      • Process creation/communication overhead dominates computation
      • Chunk synchronization and data transfer costs are high
      • Python process spawning costs are significant
  Recommendation: Use image-level strategy

Concurrent.Futures:
----------------------------------------

Workers    Time (s)     Speedup      Efficiency  
1          8.6399       0.92        x 92.06%      
2          5.0595       1.57        x 78.60%      
4          3.4359       2.31        x 57.87%      
8          2.4596       3.23        x 40.42%      

Scalability Metrics:
  • Best speedup: 3.23x (at 8 workers)
  • Speedup with 8 workers: 3.23x (Ideal: 8x)
  • Scaling efficiency: 40.4%
  • Efficiency trend: 92.1% → 78.6% → 57.9% → 40.4%

Bottleneck Analysis:
  ⚠️  POOR SCALING detected:
      • Process creation/communication overhead dominates computation
      • Chunk synchronization and data transfer costs are high
      • Python process spawning costs are significant
  Recommendation: Use image-level strategy

================================================================================
IMAGE-LEVEL PARALLELISM STRATEGY
================================================================================

Multiprocessing:
----------------------------------------

Workers    Time (s)     Speedup      Efficiency  
1          8.2907       0.96        x 95.93%      
2          8.3869       0.95        x 47.42%      
4          8.8403       0.90        x 22.49%      
8          8.8217       0.90        x 11.27%      

Scalability Metrics:
  • Best speedup: 0.96x (at 1 workers)
  • Speedup with 8 workers: 0.90x (Ideal: 8x)
  • Scaling efficiency: 11.3%
  • Efficiency trend: 95.9% → 47.4% → 22.5% → 11.3%

Bottleneck Analysis:
  ⚠️  POOR SCALING detected:
      • Process creation/communication overhead dominates computation
      • Image count too low or images too small for effective parallelization
      • Python process spawning costs are significant
  Recommendation: Use larger dataset or fewer workers

Concurrent.Futures:
----------------------------------------

Workers    Time (s)     Speedup      Efficiency  
1          8.5655       0.93        x 92.86%      
2          8.6102       0.92        x 46.19%      
4          8.4837       0.94        x 23.44%      
8          8.5072       0.93        x 11.69%      

Scalability Metrics:
  • Best speedup: 0.94x (at 4 workers)
  • Speedup with 8 workers: 0.93x (Ideal: 8x)
  • Scaling efficiency: 11.7%
  • Efficiency trend: 92.9% → 46.2% → 23.4% → 11.7%

Bottleneck Analysis:
  ⚠️  POOR SCALING detected:
      • Process creation/communication overhead dominates computation
      • Image count too low or images too small for effective parallelization
      • Python process spawning costs are significant
  Recommendation: Use larger dataset or fewer workers

================================================================================
PHASE 3B: PARALLELIZATION STRATEGY COMPARISON
================================================================================

Comparing PIXEL-LEVEL vs IMAGE-LEVEL parallelism...


Multiprocessing:
------------------------------------------------------------
  Pixel-Level:  Time=2.3889s, Speedup=3.33x, Efficiency=41.62%
  Image-Level:  Time=8.8217s, Speedup=0.90x, Efficiency=11.27%

  ✓ PIXEL-LEVEL is FASTER by 6.4327s (72.9%)
    Reason: Better parallelism within large images

Concurrent.Futures:
------------------------------------------------------------
  Pixel-Level:  Time=2.4596s, Speedup=3.23x, Efficiency=40.42%
  Image-Level:  Time=8.5072s, Speedup=0.93x, Efficiency=11.69%

  ✓ PIXEL-LEVEL is FASTER by 6.0477s (71.1%)
    Reason: Better parallelism within large images

--------------------------------------------------------------------------------

Strategy Trade-offs:

PIXEL-LEVEL (Chunk-based):
  Advantages:
    • Effective for processing very large images
    • Can parallelize even with single image
    • Granular load distribution within image
  Disadvantages:
    • High IPC overhead (data transfer between processes)
    • Chunk synchronization costs
    • Edge handling complexity (overlapping chunks)
    • Process pool overhead per image

IMAGE-LEVEL (Multi-image):
  Advantages:
    • Low IPC overhead (each process works independently)
    • Simple work distribution
    • No chunk synchronization needed
    • Better cache locality
  Disadvantages:
    • Requires multiple images to parallelize
    • Load imbalance if image sizes vary significantly
    • Cannot parallelize single image processing

Recommendation for this workload (1 images):
  ✓ Use PIXEL-LEVEL parallelism (significantly faster)
    • 72.0% faster on average
    • Better for large individual images

================================================================================
PHASE 3C: PARADIGM COMPARISON (Multiprocessing vs Concurrent.Futures)
================================================================================

Pixel-Level Strategy at 8 workers:
------------------------------------------------------------
  Multiprocessing:      Time=2.3889s, Speedup=3.33x, Efficiency=41.62%
  Concurrent.Futures:   Time=2.4596s, Speedup=3.23x, Efficiency=40.42%
  ✓ Multiprocessing is FASTER by 0.0706s (2.9%)

Image-Level Strategy at 8 workers:
------------------------------------------------------------
  Multiprocessing:      Time=8.8217s, Speedup=0.90x, Efficiency=11.27%
  Concurrent.Futures:   Time=8.5072s, Speedup=0.93x, Efficiency=11.69%
  ✓ Concurrent.Futures is FASTER by 0.3144s (3.6%)

Key Differences Between Paradigms:
  • multiprocessing.Pool: Classic API, efficient pool.map() for bulk operations
  • concurrent.futures: Modern API, better for task-based workflows
  • Both use similar underlying mechanisms (process pools)
  • Performance difference typically <5% for compute-bound tasks
  • concurrent.futures offers more flexibility for async patterns

================================================================================
PHASE 4: AMDAHL'S LAW ANALYSIS
================================================================================

Amdahl's Law: S(n) = 1 / ((1-p) + p/n)
where p = parallelizable fraction, n = number of processors

Estimating parallelizable portion from observed speedup...


================================================================================
PIXEL-LEVEL STRATEGY
================================================================================

Multiprocessing:
----------------------------------------

Observed speedup at 8 workers: 3.33x

Estimated work distribution:
  • Parallelizable portion (p): 80.0%
  • Serial portion (1-p):       20.0%

Theoretical limits (Amdahl's Law):
  • Maximum speedup (infinite processors): 4.99x
  • Current achievement: 66.7% of theoretical maximum

Projected speedups based on estimated p=0.800:
  •   2 processors:  1.67x speedup (83.3% efficiency)
  •   4 processors:  2.50x speedup (62.5% efficiency)
  •   8 processors:  3.33x speedup (41.6% efficiency)
  •  16 processors:  3.99x speedup (25.0% efficiency)
  •  32 processors:  4.44x speedup (13.9% efficiency)
  •  64 processors:  4.70x speedup ( 7.3% efficiency)

Concurrent.Futures:
----------------------------------------

Observed speedup at 8 workers: 3.23x

Estimated work distribution:
  • Parallelizable portion (p): 78.9%
  • Serial portion (1-p):       21.1%

Theoretical limits (Amdahl's Law):
  • Maximum speedup (infinite processors): 4.75x
  • Current achievement: 68.1% of theoretical maximum

Projected speedups based on estimated p=0.789:
  •   2 processors:  1.65x speedup (82.6% efficiency)
  •   4 processors:  2.45x speedup (61.3% efficiency)
  •   8 processors:  3.23x speedup (40.4% efficiency)
  •  16 processors:  3.85x speedup (24.0% efficiency)
  •  32 processors:  4.25x speedup (13.3% efficiency)
  •  64 processors:  4.49x speedup ( 7.0% efficiency)

================================================================================
IMAGE-LEVEL STRATEGY
================================================================================

Multiprocessing:
----------------------------------------

Observed speedup at 8 workers: 0.90x

Estimated work distribution:
  • Parallelizable portion (p): 0.0%
  • Serial portion (1-p):       100.0%

Theoretical limits (Amdahl's Law):
  • Maximum speedup (infinite processors): 1.00x
  • Current achievement: 90.2% of theoretical maximum

Projected speedups based on estimated p=0.000:
  •   2 processors:  1.00x speedup (50.0% efficiency)
  •   4 processors:  1.00x speedup (25.0% efficiency)
  •   8 processors:  1.00x speedup (12.5% efficiency)
  •  16 processors:  1.00x speedup ( 6.2% efficiency)
  •  32 processors:  1.00x speedup ( 3.1% efficiency)
  •  64 processors:  1.00x speedup ( 1.6% efficiency)

Concurrent.Futures:
----------------------------------------

Observed speedup at 8 workers: 0.93x

Estimated work distribution:
  • Parallelizable portion (p): 0.0%
  • Serial portion (1-p):       100.0%

Theoretical limits (Amdahl's Law):
  • Maximum speedup (infinite processors): 1.00x
  • Current achievement: 93.5% of theoretical maximum

Projected speedups based on estimated p=0.000:
  •   2 processors:  1.00x speedup (50.0% efficiency)
  •   4 processors:  1.00x speedup (25.0% efficiency)
  •   8 processors:  1.00x speedup (12.5% efficiency)
  •  16 processors:  1.00x speedup ( 6.2% efficiency)
  •  32 processors:  1.00x speedup ( 3.1% efficiency)
  •  64 processors:  1.00x speedup ( 1.6% efficiency)

================================================================================
PHASE 5B: SAVING RESULTS TO FILES
================================================================================
✓ Saved CSV: ./output_images_test\benchmark_results.csv
✓ Saved JSON: ./output_images_test\benchmark_results.json

================================================================================
PHASE 5C: GENERATING PERFORMANCE VISUALIZATIONS
================================================================================

Creating performance charts...
✓ Saved: ./output_images_test\performance_analysis.png

================================================================================
BENCHMARK COMPLETE
================================================================================

Summary:
  • Processed 1 images through 5-filter pipeline
  • Sequential baseline: 7.9536s
  • Best parallel time: 2.3889s (Pixel-Level - Multiprocessing - 8 workers)
  • Maximum speedup achieved: 3.33x
  • Overall speedup: 3.33x faster than sequential

Strategies Tested:
  1. PIXEL-LEVEL: Divide each image into chunks, process chunks in parallel
  2. IMAGE-LEVEL: Process multiple images concurrently

Paradigms Tested:
  1. multiprocessing.Pool (classic process pool API)
  2. concurrent.futures.ProcessPoolExecutor (modern async API)

Output Files Generated:
  • Processed images: ./output_images_test/
  • Benchmark output: ./output_images_test\benchmark_output.txt
  • Performance chart: ./output_images_test\performance_analysis.png
  • Results (CSV): ./output_images_test\benchmark_results.csv
  • Results (JSON): ./output_images_test\benchmark_results.json

Filters applied (in order):
  1. Grayscale Conversion (ITU-R BT.601 luminance formula)
  2. Gaussian Blur (3×3 kernel smoothing)
  3. Image Sharpening (edge enhancement)
  4. Edge Detection (Sobel operator)
  5. Brightness Adjustment (1.2x factor)

================================================================================
